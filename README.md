## SALD-Net: Self-attention-integrated LiDAR-based 3D object detection network in a crowded hospital environment

SALD-Net is a self-attention-integrated LiDAR-based 3D object detection framework designed for **autonomous robot navigation** in complex environments such as hospitals. SALD-Net enhances detection accuracy for small and occluded objects through tailored attention mechanisms (BAM & RAM) and point cloud augmentation.

## ğŸ“‘ Table of Contents
- [Changelog](#changelog)
- [Design Pattern](#design-pattern)
- [Model Zoo](#model-zoo)
- [Installation](#installation)
- [Quick Demo](#quick-demo)
- [Getting Started](#getting-started)
- [Citation](#citation)

---

## ğŸ§© Changelog

- **[2025.10.28]** Initial version of SALD-Net uploaded.
- **[2025.11.xx]** Add demo video and pretrained model links.

---

## ğŸ§  Design Pattern

- Backbone: Point-based feature extraction  
- Head: Unified Regional & Grid (URG) RoI pooling  
- Self-Attention modules: BAM / RAM  
- Framework overview diagram (ì¶”ê°€ ì˜ˆì •)

---

## ğŸ§° Model Zoo

| Model | BEV mAP (%) | 3D mAP (%) | Dataset | Download |
|:------|:-------------:|:-------------:|:----------|:----------|
| SALD-Net (Base) | 90.03 | 89.08 | Hospital-LiDAR | [model link](#) |

---

## âš™ï¸ Installation

```bash
# 1. í™˜ê²½ ì„¤ì •
conda create -n saldnet python=3.8
conda activate saldnet

# 2. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt

# 3. CUDA í™˜ê²½ í…ŒìŠ¤íŠ¸
python demo/test_cuda.py
